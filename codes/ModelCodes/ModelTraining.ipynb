{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Part"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "\n",
    "class_to_name = {}\n",
    "dataset_path = r\"E:\\Python_Projeler\\ComputerVisionProjects\\FinalProject\\dataset\\main01\"\n",
    "num_classes = 34\n",
    "epoch_amount = 200\n",
    "batch_size = 32\n",
    "rotation = 10\n",
    "terminate_epoch = 75\n",
    "\n",
    "charInt2Name = {\n",
    "    0: '0',\n",
    "    1: '1',\n",
    "    2: '2',\n",
    "    3: '3',\n",
    "    4: '4',\n",
    "    5: '5',\n",
    "    6: '6',\n",
    "    7: '7',\n",
    "    8: '8',\n",
    "    9: '9',\n",
    "    10: 'a',\n",
    "    11: 'b',\n",
    "    12: 'c',\n",
    "    13: 'd',\n",
    "    14: 'e',\n",
    "    15: 'f',\n",
    "    16: 'h',\n",
    "    17: 'horizontal_line',\n",
    "    18: 'n',\n",
    "    19: 'o',\n",
    "    20: 'p',\n",
    "    21: 'paranthesis_left',\n",
    "    22: 'paranthesis_right',\n",
    "    23: 'plus',\n",
    "    24: 'r',\n",
    "    25: 'slash',\n",
    "    26: 'sqrt',\n",
    "    27: 't',\n",
    "    28: 'u',\n",
    "    29: 'v',\n",
    "    30: 'vertical_line',\n",
    "    31: 'w',\n",
    "    32: 'x',\n",
    "    33: 'y'\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "class iztechCNN(nn.Module):\n",
    "    def __init__(self, num_classes = num_classes):\n",
    "        super(iztechCNN,self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3,padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3,padding=1)\n",
    "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "\n",
    "        self.fc1 = nn.Linear(128 * 8 * 8, 256)\n",
    "        self.fc2 = nn.Linear(256, num_classes)\n",
    "    def forward(self,x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = self.pool(F.relu(self.conv3(x)))\n",
    "\n",
    "        x = x.view(-1, 128 * 8 * 8)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return self.fc2(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform\n",
    "\n",
    "The purpose of this part is to make the images in the dataset have more variety in every epoch. This part may be used to normalize the datasets as well, even simultaneosly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.RandomRotation(rotation),  # simple rotation augment\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "full_dataset  = datasets.ImageFolder(r'E:\\Python_Projeler\\ComputerVisionProjects\\FinalProject\\dataset\\main01', transform=transform)\n",
    "\n",
    "train_size = int(0.8 * len(full_dataset))\n",
    "val_size = len(full_dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking if PyTorch recognizes my GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device) \n",
    "print(torch.cuda.get_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = iztechCNN(num_classes=num_classes).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "counter = 0\n",
    "\n",
    "biggest = 0.0\n",
    "most_accurate_model = None\n",
    "\n",
    "for epoch in range(epoch_amount):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if i % 10 == 9:\n",
    "            print(f\"[Epoch {epoch+1}, Batch {i+1}] Train Loss: {loss.item():.4f}\")\n",
    "\n",
    "    avg_train_loss = running_loss / len(train_loader)\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    print(f\"[Epoch {epoch+1}] Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "\n",
    "    if counter == terminate_epoch:\n",
    "        print(f\"There are no further improve in the last 50 epochs. Training terminates itself.\")\n",
    "        break\n",
    "\n",
    "    if accuracy <= biggest:\n",
    "        counter += 1\n",
    "        continue\n",
    "    \n",
    "    counter = 0\n",
    "    biggest = accuracy\n",
    "    most_accurate_model = model\n",
    "\n",
    "print(f\"Biggest Accuracy : {biggest}\")\n",
    "        \n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "model_number = len(os.listdir(\"models/\"))\n",
    "\n",
    "save_name = f'models/charcnn_{model_number}.pth'\n",
    "\n",
    "torch.save(most_accurate_model.state_dict(), save_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "horizontal_line\n",
      "o\n",
      "horizontal_line\n",
      "u\n",
      "b\n",
      "b\n"
     ]
    }
   ],
   "source": [
    "import cv2 \n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "\n",
    "test_model = iztechCNN(num_classes=num_classes)\n",
    "\n",
    "test_model.load_state_dict(torch.load(r\"E:\\Python_Projeler\\ComputerVisionProjects\\FinalProject\\codes\\ModelCodes\\models\\charcnn_2.pth\",map_location = \"cuda\",weights_only=True))\n",
    "test_model.eval()\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "img = cv2.imread(r\"E:\\Python_Projeler\\ComputerVisionProjects\\FinalProject\\codes\\ModelCodes\\TestImages\\deneme_2.png\", cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "blur = cv2.GaussianBlur(img,(3,3),1)\n",
    "\n",
    "_, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "for index, contour in enumerate(contours):\n",
    "    x, y, w, h = cv2.boundingRect(contour)\n",
    "    max_edge = max(w,h)\n",
    "\n",
    "    blank = np.zeros((max_edge,max_edge))\n",
    "\n",
    "    x1,x2 = int( (max_edge - h) / 2 ), int( (max_edge + h) / 2 )\n",
    "    y1,y2 = int( (max_edge - w) / 2 ), int( (max_edge + w) / 2 )\n",
    "\n",
    "    blank[x1:x2,y1:y2] = thresh[y:y+h, x:x+w]\n",
    "    letter = cv2.resize(blank, (64,64))\n",
    "    cv2.imshow(\"lala\",letter)\n",
    "        \n",
    "    letter = transform(letter)\n",
    "    letter = letter.float()\n",
    "    letter = letter.unsqueeze(0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        output = test_model(letter)\n",
    "        _, predicted = torch.max(output, 1)\n",
    "\n",
    "        charInt = predicted.tolist()[0]\n",
    "        print(charInt2Name[charInt])\n",
    "    cv2.waitKey(0)\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
