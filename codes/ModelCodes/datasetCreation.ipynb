{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KaggleDownload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Looks like you're using an outdated `kagglehub` version (installed: 0.3.6), please consider upgrading to the latest version (0.3.12).\n",
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/tmdb/tmdb-movie-metadata?dataset_version_number=2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8.89M/8.89M [00:01<00:00, 7.33MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to dataset files: C:\\Users\\EnderEfe\\.cache\\kagglehub\\datasets\\tmdb\\tmdb-movie-metadata\\versions\\2\n"
     ]
    }
   ],
   "source": [
    "import kagglehub\n",
    "\n",
    "path = kagglehub.dataset_download(\"tmdb/tmdb-movie-metadata\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Dataset Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Required Libraries and Definings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "dataset_path = r\"E:\\\\Python_Projeler\\\\ComputerVisionProjects\\\\FinalProject\\\\dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "letter_dict = {\n",
    "    '0001': 'a', '0002': 'b', '0003': 'c', '0004': 'd', '0005': 'e', '0006': 'f',\n",
    "    '0007': 'h', '0008': 'vertical_line', '0009': 'j', '0010': 'k', '0011': 'vertical_line',\n",
    "    '0012': 'm', '0013': 'n', '0014': 'o', '0015': 'p', '0016': 'q', '0017': 'r',\n",
    "    '0018': 's', '0019': 't', '0020': 'u', '0021': 'v', '0022': 'w', '0023': 'x',\n",
    "    '0024': 'y', '0025': 'z', '0026': '0', '0027': '1', '0028': '2', '0029': '3',\n",
    "    '0030': '4', '0031': '5', '0032': '6', '0033': '7', '0034': '8', '0035': '9',\n",
    "    '0036': 'plus', '0037': 'horizontal_line', '0038': 'slash',\n",
    "    '0039': 'paranthesis_left', '0040': 'paranthesis_right', '0041': 'sqrt', '0042': 'sqrt'}\n",
    "\n",
    "label_dict = {label: 0 for label in set(letter_dict.values())}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character Extraction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractSet(path, save_path, name=None):\n",
    "    page = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    kernel = np.ones((4, 4), np.uint8)\n",
    "    blur = cv2.GaussianBlur(page, (3, 3), 1)\n",
    "    _, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)\n",
    "\n",
    "    dilation = cv2.dilate(thresh, kernel, iterations=2)\n",
    "    dilation_2 = cv2.dilate(thresh, kernel=np.ones((1, 1), np.uint8))  # Optional, may vary per dataset\n",
    "\n",
    "    contours, _ = cv2.findContours(dilation, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    for index, contour in enumerate(contours):\n",
    "        mask = np.zeros_like(dilation)\n",
    "        cv2.drawContours(mask, [contour], -1, 255, thickness=cv2.FILLED)\n",
    "        MaskedLetter = cv2.bitwise_and(dilation_2, dilation_2, mask=mask)\n",
    "\n",
    "        if name is not None:\n",
    "            index = label_dict[name]\n",
    "            label_dict[name] = index + 1\n",
    "\n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        max_edge = max(h, w)\n",
    "        blank = np.zeros((max_edge, max_edge), np.uint8)\n",
    "\n",
    "        x1, x2 = int((max_edge - h) / 2), int((max_edge + h) / 2)\n",
    "        y1, y2 = int((max_edge - w) / 2), int((max_edge + w) / 2)\n",
    "\n",
    "        blank[x1:x2, y1:y2] = MaskedLetter[y:y + h, x:x + w]\n",
    "        letter = cv2.resize(blank, (64, 64))\n",
    "\n",
    "        cv2.imwrite(save_path + f\"\\\\{index}.jpg\", letter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process Dataset Image Pages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dSet_folder in os.listdir(dataset_path):\n",
    "    if len(dSet_folder.split(\".\")) > 1:\n",
    "        continue\n",
    "\n",
    "    dSet_path = os.path.join(dataset_path, dSet_folder)\n",
    "\n",
    "    for index, letter_page in enumerate(os.listdir(dSet_path)):\n",
    "        if letter_page.split(\".\")[-1] != \"jpg\":\n",
    "            continue\n",
    "\n",
    "        letter_page_path = os.path.join(dSet_path, letter_page)\n",
    "        letter_number = letter_page.split(\".\")[0].split(\"-\")[-1]\n",
    "        letter_name = letter_dict[letter_number]\n",
    "\n",
    "        print(f\"{letter_name}        {letter_number}\")\n",
    "\n",
    "        save_path = os.path.join(dSet_path, letter_name)\n",
    "        os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "        ExtractSet(letter_page_path, save_path, letter_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EMNIST Extracting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import gzip\n",
    "\n",
    "EMNIST_type = \"balanced\"\n",
    "\n",
    "#This Mapping is for balanced ONLY!! You have to check emnist-TYPE-mapping.txt file to correct the mapping!\n",
    "LabelMapping = {\n",
    "    0: \"0\",\n",
    "    1: \"1\",\n",
    "    2: \"2\",\n",
    "    3: \"3\",\n",
    "    4: \"4\",\n",
    "    5: \"5\",\n",
    "    6: \"6\",\n",
    "    7: \"7\",\n",
    "    8: \"8\",\n",
    "    9: \"9\",\n",
    "    10: None,\n",
    "    11: None,\n",
    "    12: \"upper_c\",\n",
    "    13: None,\n",
    "    14: None,\n",
    "    15: None,\n",
    "    16: None,\n",
    "    17: None,\n",
    "    18: None,\n",
    "    19: \"upper_j\",\n",
    "    20: \"upper_k\",\n",
    "    21: \"upper_l\",\n",
    "    22: \"upper_m\",\n",
    "    23: None,\n",
    "    24: \"upper_o\",\n",
    "    25: \"upper_p\",\n",
    "    26: None,\n",
    "    27: None,\n",
    "    28: \"upper_s\",\n",
    "    29: None,\n",
    "    30: \"upper_u\",\n",
    "    31: \"upper_v\",\n",
    "    32: \"upper_w\",\n",
    "    33: \"upper_x\",\n",
    "    34: \"upper_y\",\n",
    "    35: \"upper_z\",\n",
    "    36: \"lower_a\",\n",
    "    37: \"lower_b\",\n",
    "    38: \"lower_d\",\n",
    "    39: \"lower_e\",\n",
    "    40: \"lower_f\",\n",
    "    41: \"lower_g\",\n",
    "    42: \"lower_h\",\n",
    "    43: \"lower_n\",\n",
    "    44: \"lower_q\",\n",
    "    45: \"lower_r\",\n",
    "    46: \"lower_t\"\n",
    "}\n",
    "\n",
    "\n",
    "notWanted = ['k', \"j\",\"m\", \"q\", \"z\", \"v\",\"u\"]\n",
    "\n",
    "LabelCounter = {\n",
    "    \"0\": 0,\n",
    "    \"1\": 0,\n",
    "    \"2\": 0,\n",
    "    \"3\": 0,\n",
    "    \"4\": 0,\n",
    "    \"5\": 0,\n",
    "    \"6\": 0,\n",
    "    \"7\": 0,\n",
    "    \"9\": 0,\n",
    "    \"8\": 0,\n",
    "    \"z\": 0,\n",
    "    \"a\": 0,\n",
    "    \"b\": 0,\n",
    "    \"c\": 0,\n",
    "    \"d\": 0,\n",
    "    \"e\": 0,\n",
    "    \"f\": 0,\n",
    "    \"g\": 0,\n",
    "    \"h\": 0,\n",
    "    \"i\": 0,\n",
    "    \"j\": 0,\n",
    "    \"k\": 0,\n",
    "    \"l\": 0,\n",
    "    \"m\": 0,\n",
    "    \"n\": 0,\n",
    "    \"o\": 0,\n",
    "    \"p\": 0,\n",
    "    \"q\": 0,\n",
    "    \"r\": 0,\n",
    "    \"s\": 0,\n",
    "    \"t\": 0,\n",
    "    \"u\": 0,\n",
    "    \"v\": 0,\n",
    "    \"w\": 0,\n",
    "    \"x\": 0,\n",
    "    \"y\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadIdxImage(file):\n",
    "    with gzip.open(file,\"rb\") as F:\n",
    "        \n",
    "        magic_number = int.from_bytes(F.read(4), 'big') \n",
    "        num_items = int.from_bytes(F.read(4), 'big')  \n",
    "        num_rows = int.from_bytes(F.read(4), 'big') \n",
    "        num_cols = int.from_bytes(F.read(4), 'big')  \n",
    "\n",
    "        data = np.frombuffer(F.read(),dtype = np.uint8)\n",
    "        data = data.reshape(num_items,num_rows,num_cols)\n",
    "\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "def ReadIdxLabel(file):\n",
    "    with gzip.open(file,\"rb\") as F:\n",
    "\n",
    "        F.read(8)\n",
    "\n",
    "    \n",
    "        return F.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder ../../dataset/EMNIST/balanced/train/0 is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/train/1 is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/train/2 is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/train/3 is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/train/4 is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/train/5 is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/train/6 is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/train/7 is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/train/8 is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/train/9 is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/train/c is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/train/j is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/train/k is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/train/l is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/train/m is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/train/o is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/train/p is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/train/s is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/train/u is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/train/v is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/train/w is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/train/x is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/train/y is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/train/z is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/train/a is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/train/b is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/train/d is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/train/e is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/train/f is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/train/g is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/train/h is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/train/n is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/train/q is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/train/r is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/train/t is created or already exists\n",
      "EMNIST Dataset Extraction is completed.\n",
      "{'0': 2400, '1': 2400, '2': 2400, '3': 2400, '4': 2400, '5': 2400, '6': 2400, '7': 2400, '9': 2400, '8': 2400, 'z': 2400, 'a': 2400, 'b': 2400, 'c': 2400, 'd': 2400, 'e': 2400, 'f': 2400, 'g': 2400, 'h': 2400, 'i': 0, 'j': 2400, 'k': 2400, 'l': 2400, 'm': 2400, 'n': 2400, 'o': 2400, 'p': 2400, 'q': 2400, 'r': 2400, 's': 2400, 't': 2400, 'u': 2400, 'v': 2400, 'w': 2400, 'x': 2400, 'y': 2400}\n",
      "Folder ../../dataset/EMNIST/balanced/test/0 is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/test/1 is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/test/2 is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/test/3 is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/test/4 is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/test/5 is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/test/6 is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/test/7 is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/test/8 is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/test/9 is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/test/c is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/test/j is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/test/k is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/test/l is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/test/m is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/test/o is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/test/p is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/test/s is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/test/u is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/test/v is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/test/w is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/test/x is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/test/y is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/test/z is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/test/a is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/test/b is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/test/d is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/test/e is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/test/f is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/test/g is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/test/h is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/test/n is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/test/q is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/test/r is created or already exists\n",
      "Folder ../../dataset/EMNIST/balanced/test/t is created or already exists\n",
      "EMNIST Dataset Extraction is completed.\n",
      "{'0': 2800, '1': 2800, '2': 2800, '3': 2800, '4': 2800, '5': 2800, '6': 2800, '7': 2800, '9': 2800, '8': 2800, 'z': 2800, 'a': 2800, 'b': 2800, 'c': 2800, 'd': 2800, 'e': 2800, 'f': 2800, 'g': 2800, 'h': 2800, 'i': 0, 'j': 2800, 'k': 2800, 'l': 2800, 'm': 2800, 'n': 2800, 'o': 2800, 'p': 2800, 'q': 2800, 'r': 2800, 's': 2800, 't': 2800, 'u': 2800, 'v': 2800, 'w': 2800, 'x': 2800, 'y': 2800}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for train_or_test in [\"train\", \"test\"]:\n",
    "    \n",
    "    images_path = r\"EMNIST/\"+EMNIST_type+r\"/emnist-\"+EMNIST_type+r\"-\"+train_or_test+\"-images-idx3-ubyte.gz\"\n",
    "    labels_path = r\"EMNIST/\"+EMNIST_type+r\"/emnist-\"+EMNIST_type+r\"-\"+train_or_test+\"-labels-idx1-ubyte.gz\"\n",
    "\n",
    "    save_path = r\"../../dataset/EMNIST/\"+EMNIST_type + r\"/\" +train_or_test\n",
    "\n",
    "\n",
    "\n",
    "    os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "    images = ReadIdxImage(images_path)\n",
    "\n",
    "    labels = ReadIdxLabel(labels_path)\n",
    "\n",
    "    for label in LabelMapping:\n",
    "        \n",
    "        char = LabelMapping[label]\n",
    "        if char is None:    continue\n",
    "        char = char[-1]\n",
    "        \n",
    "        path = save_path + r\"/\" + char\n",
    "        os.makedirs(path, exist_ok=True )\n",
    "        print(f\"Folder {path} is created or already exists\")\n",
    "\n",
    "\n",
    "\n",
    "    error_text = \"\"\n",
    "\n",
    "    for i,(image, label) in enumerate(zip(images,labels)):\n",
    "        if LabelMapping[label] is None:\n",
    "            continue\n",
    "\n",
    "        char = LabelMapping[label][-1]\n",
    "        \n",
    "        if char in notWanted:   \n",
    "            LabelCounter[char] += 1\n",
    "            continue\n",
    "\n",
    "        char_index = LabelCounter[char]  \n",
    "\n",
    "        try:\n",
    "            save = save_path + r\"/\" + char +r\"/\"\n",
    "\n",
    "            image = cv2.resize(image,(48,48), interpolation=cv2.INTER_NEAREST)\n",
    "            cv2.imwrite(save + f\"{char_index}.png\",image.T)\n",
    "            LabelCounter[char] += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            error_text+= f\"There was an error on {char} - {EMNIST_type}  -    Error: {e}\\n\\n\"\n",
    "\n",
    "    with open(\"/datasetC_error_log.txt\", \"a+\") as F:\n",
    "        F.write(error_text)\n",
    "\n",
    "    print(f\"EMNIST Dataset Extraction is completed.\")\n",
    "    print(LabelCounter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Operators Dilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = r\"../../dataset/Operators/\"\n",
    "\n",
    "for foder in os.listdir(path):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All Sets Combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMNIST_balanced_path = r\"../../dataset/EMNIST/balanced/\"\n",
    "Operator_path = r\"../../dataset/Operators/\"\n",
    "Custom_set_1 = r\"../../dataset/berna\"\n",
    "Custom_set_2 = r\"../../dataset/ender\"\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
